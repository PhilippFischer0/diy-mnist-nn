{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comfy Kettenregel (Autograd DIY) - univariate, skalare Funktionen\n",
    "\n",
    "$$F(x) = f_1 \\circ f_2 = f_1(f_2(x)) \\Rightarrow f_1'(f_2(x)) \\cdot f'_2(x)$$\n",
    "\n",
    "$$F(x) = f_1 \\circ f_2 \\circ f_3 = f_1(f_2(f_3(x))) \\Rightarrow f_1'(f_2(f_3(x))) \\cdot f_2'(f_3\n",
    "(x)) \\cdot f_3'(x)$$\n",
    "\n",
    "## Aufgabe\n",
    "\n",
    "Ziel: Gradientenbasierte Optimierung von $f(x) = \\sqrt{\\frac{1}{e^{\\sin(x)}}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Operationen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_div_x(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = 1 / x\n",
    "    derivative = -inner_derivative / x**2\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def sin(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.sin(x)\n",
    "    derivative = math.cos(x) * inner_derivative\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def sqrt(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.sqrt(x)\n",
    "    derivative = 1 / (2 * math.sqrt(x)) * inner_derivative\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def exp(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.exp(x)\n",
    "    derivative = math.exp(x) * inner_derivative\n",
    "\n",
    "    return value, derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Funktionsdefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(x: float) -> tuple[float, float]:\n",
    "\n",
    "    return sqrt(*one_div_x(*exp(*sin(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 4.0  # starting value\n",
    "x_min = x_start - 8.0  # x-axis limits\n",
    "x_max = x_start + 8.0\n",
    "xs = []  # values for the animation\n",
    "ys = []\n",
    "\n",
    "lr = 1e-2  # step size\n",
    "significant_gradient = 1e-3  # termination criteria\n",
    "iter = 1  # counter\n",
    "\n",
    "while True:\n",
    "    y, deriv = f_x(x_start)\n",
    "    if np.fabs(deriv) >= significant_gradient:\n",
    "        xs.append(x_start)\n",
    "        ys.append(y)\n",
    "        x_start -= lr * deriv\n",
    "        print(iter, x_start, y) if iter % 100 == 0 or iter == 1 else None\n",
    "    else:\n",
    "        xs.append(x_start)\n",
    "        ys.append(y)\n",
    "        break\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Funktionsplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(x_min, x_max, 0.01)\n",
    "\n",
    "res = [f_x(_) for _ in x]\n",
    "y, derivative = zip(*res)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"derivative\": derivative,\n",
    "    }\n",
    ")\n",
    "\n",
    "px.line(df, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values\n",
    "x = np.arange(x_min, x_max, 0.01)\n",
    "\n",
    "res = [f_x(_) for _ in x]\n",
    "y, _ = zip(*res)\n",
    "\n",
    "# define both graphs\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"green\", width=1),\n",
    "            name=\"Function Graph\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[xs[0]],\n",
    "            y=[ys[0]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"red\", size=10),\n",
    "            name=\"Current Position\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# update layout parameters and add start button for animation\n",
    "fig.update_layout(\n",
    "    width=1400,\n",
    "    height=900,\n",
    "    xaxis=dict(range=(x_min, x_max), autorange=False),\n",
    "    yaxis=dict(range=(np.min(y) - 0.5, np.max(y) + 0.5), autorange=False),\n",
    "    title_text=\"Gradient Descent Animation\",\n",
    "    # start button config\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 5, \"redraw\": False},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"transition\": {\"duration\": 0, \"easing\": \"linear\"},\n",
    "                        },\n",
    "                    ],\n",
    "                    label=\"start\",\n",
    "                    method=\"animate\",\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# specify the animation frames\n",
    "fig.update(\n",
    "    frames=[\n",
    "        go.Frame(data=[go.Scatter(x=[xs[k]], y=[ys[k]])], traces=[1])\n",
    "        for k in range(len(ys))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# show result\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-11-18 \n",
    "\n",
    "Bisherige Ansatz hat folgende Limitierungen\n",
    "- funktioniert nur f체r Ausdr체cke in geschlossener Form, keine Kontrollflusslogik\n",
    "- inkompatibel mit bin채ren Operatoren (+, *, ...)\n",
    "- funktioniert nur in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, value: float, ancestors: tuple[Value, ...] = (), name=\"\"):\n",
    "        self.value = value\n",
    "        self.ancestors = ancestors\n",
    "        self.name = name\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        # TODO add separate nodes for operations\n",
    "\n",
    "    # make values printable\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}, value={self.value}, grad={self.grad}\"\n",
    "\n",
    "    # Addition\n",
    "    def __add__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value + other.value, (self, other), name=\"add\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * result.grad\n",
    "            other.grad += 1.0 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Subtraktion\n",
    "    def __sub__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value - other.value, (self, other), name=\"sub\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * result.grad\n",
    "            other.grad += -1.0 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Multiplikation\n",
    "    def __mul__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value * other.value, (self, other), name=\"mul\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * result.grad\n",
    "            other.grad += self.value * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Floatingpointdivision\n",
    "    def __truediv__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value / other.value, (self, other), name=\"div\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1 / other.value * result.grad\n",
    "            other.grad += -self.value / other.value**2 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Potenzierung (x**n)\n",
    "    def __pow__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value**other.value, (self, other), name=\"pow\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * self.value ** (other.value - 1) * result.grad\n",
    "            assert self.value >= 0, \"cannot compute log with negative bases\"\n",
    "            other.grad += self.value**other.value * np.log(self.value) * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # backwards up until this point\n",
    "    # Negation\n",
    "    def __neg__(self) -> Value:\n",
    "        result = Value(-self.value, (self,), name=\"neg\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += -result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Vergleichsoperatoren <, >, >=, <=, ==, !=\n",
    "    def __lt__(self, other: Value) -> bool:\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __gt__(self, other: Value) -> bool:\n",
    "        return self.value > other.value\n",
    "\n",
    "    def __le__(self, other: Value) -> bool:\n",
    "        return self.value <= other.value\n",
    "\n",
    "    def __ge__(self, other: Value) -> bool:\n",
    "        return self.value >= other.value\n",
    "\n",
    "    def __eq__(self, other: Value) -> bool:\n",
    "        return self.value == other.value\n",
    "\n",
    "    def __ne__(self, other: Value) -> bool:\n",
    "        return self.value != other.value\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.value)\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        # iterate through the graph, calculate gradients and update nodes\n",
    "        topo_sorted_nodes = []\n",
    "        visited = set()\n",
    "\n",
    "        # topological sort of the nodes\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                for ancestor in node.ancestors:\n",
    "                    build_topo(ancestor)\n",
    "                topo_sorted_nodes.append(node)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo_sorted_nodes):\n",
    "            node._backward()\n",
    "\n",
    "    def build_graph(self) -> dict:\n",
    "        def build_node(node) -> dict:\n",
    "            label = node.__repr__()\n",
    "            if node.ancestors:\n",
    "                return {\n",
    "                    label: [build_node(ancestor) for ancestor in node.ancestors],\n",
    "                }\n",
    "            else:\n",
    "                return {label: []}\n",
    "\n",
    "        return build_node(self)\n",
    "\n",
    "    # TODO: Input Variablen farbig\n",
    "    @staticmethod\n",
    "    def plot_graph(graph_dict: dict):\n",
    "        # \"graph visualization python\", graphviz\n",
    "        def add_edges(dot: graphviz.Digraph, graph: dict, ancestor_key=None):\n",
    "            for label, ancestors in graph.items():\n",
    "                if ancestor_key:\n",
    "                    dot.edge(label, ancestor_key)\n",
    "                for ancestor in ancestors:\n",
    "                    add_edges(dot, ancestor, label)\n",
    "\n",
    "        dot = graphviz.Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
    "        add_edges(dot, graph_dict)\n",
    "        # dot.render(\"graph\")\n",
    "        display(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "x = Value(5.0, name=\"x\")\n",
    "y = Value(2.5, name=\"y\")\n",
    "\n",
    "a = Value(2.5, name=\"a\")\n",
    "b = Value(3.0, name=\"b\")\n",
    "c = Value(1.5, name=\"c\")\n",
    "\n",
    "# Folgendes sollte ausf체hbar sein:\n",
    "print(x + y)\n",
    "print(x * y)\n",
    "print(x - y)\n",
    "print(x / y)\n",
    "print(x**y)\n",
    "print(x**5)\n",
    "print(-x)\n",
    "print(x == y)\n",
    "\n",
    "\n",
    "def foo(a: Value, b: Value, c: Value):\n",
    "    if a > Value(2):\n",
    "        return a * b + c\n",
    "    return a - b * c\n",
    "\n",
    "\n",
    "def f(a: Value, b: Value, c: Value) -> float:\n",
    "    # (((b**2) * c) + a)\n",
    "    x = b**2 * c\n",
    "    y = a + x\n",
    "    return y\n",
    "\n",
    "\n",
    "z1 = foo(a, b, c)\n",
    "graph = z1.build_graph()\n",
    "Value.plot_graph(graph)\n",
    "\n",
    "z2 = foo(Value(-1, name=\"a2\"), b, c)\n",
    "graph = z2.build_graph()\n",
    "Value.plot_graph(graph)\n",
    "\n",
    "z3 = f(a, b, c)\n",
    "graph = z3.build_graph()\n",
    "Value.plot_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1.backward()\n",
    "graph = z1.build_graph()\n",
    "Value.plot_graph(graph)\n",
    "\n",
    "z3.backward()\n",
    "graph3 = z3.build_graph()\n",
    "Value.plot_graph(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct(x, y):\n",
    "    return (x + y) ** 2\n",
    "\n",
    "\n",
    "x = Value(2.5, name=\"x\")\n",
    "y = Value(5.0, name=\"y\")\n",
    "\n",
    "vals = funct(x, y)\n",
    "vals.backward()\n",
    "Value.plot_graph(vals.build_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diy-mnist-nn-ZXZBkNkJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
