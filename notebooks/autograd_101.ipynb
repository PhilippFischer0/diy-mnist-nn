{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comfy Kettenregel (Autograd DIY) - univariate, skalare Funktionen\n",
    "\n",
    "$$F(x) = f_1 \\circ f_2 = f_1(f_2(x)) \\Rightarrow f_1'(f_2(x)) \\cdot f'_2(x)$$\n",
    "\n",
    "$$F(x) = f_1 \\circ f_2 \\circ f_3 = f_1(f_2(f_3(x))) \\Rightarrow f_1'(f_2(f_3(x))) \\cdot f_2'(f_3\n",
    "(x)) \\cdot f_3'(x)$$\n",
    "\n",
    "## Aufgabe\n",
    "\n",
    "Ziel: Gradientenbasierte Optimierung von $f(x) = \\sqrt{\\frac{1}{e^{\\sin(x)}}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Operationen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_div_x(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = 1 / x\n",
    "    derivative = -inner_derivative / x**2\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def sin(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.sin(x)\n",
    "    derivative = math.cos(x) * inner_derivative\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def sqrt(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.sqrt(x)\n",
    "    derivative = 1 / (2 * math.sqrt(x)) * inner_derivative\n",
    "\n",
    "    return value, derivative\n",
    "\n",
    "\n",
    "def exp(x: float, inner_derivative: float = 1) -> tuple[float, float]:\n",
    "\n",
    "    value = math.exp(x)\n",
    "    derivative = math.exp(x) * inner_derivative\n",
    "\n",
    "    return value, derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Funktionsdefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(x: float) -> tuple[float, float]:\n",
    "\n",
    "    return sqrt(*one_div_x(*exp(*sin(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 4.0  # starting value\n",
    "x_min = x_start - 8.0  # x-axis limits\n",
    "x_max = x_start + 8.0\n",
    "xs = []  # values for the animation\n",
    "ys = []\n",
    "\n",
    "lr = 1e-2  # step size\n",
    "significant_gradient = 1e-3  # termination criteria\n",
    "iter = 1  # counter\n",
    "\n",
    "while True:\n",
    "    y_measured, deriv = f_x(x_start)\n",
    "    if np.fabs(deriv) >= significant_gradient:\n",
    "        xs.append(x_start)\n",
    "        ys.append(y_measured)\n",
    "        x_start -= lr * deriv\n",
    "        print(iter, x_start, y_measured) if iter % 100 == 0 or iter == 1 else None\n",
    "    else:\n",
    "        xs.append(x_start)\n",
    "        ys.append(y_measured)\n",
    "        break\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Funktionsplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(x_min, x_max, 0.01)\n",
    "\n",
    "res = [f_x(_) for _ in x]\n",
    "y_measured, derivative = zip(*res)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": x,\n",
    "        \"y\": y_measured,\n",
    "        \"derivative\": derivative,\n",
    "    }\n",
    ")\n",
    "\n",
    "px.line(df, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values\n",
    "x = np.arange(x_min, x_max, 0.01)\n",
    "\n",
    "res = [f_x(_) for _ in x]\n",
    "y_measured, _ = zip(*res)\n",
    "\n",
    "# define both graphs\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y_measured,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"green\", width=1),\n",
    "            name=\"Function Graph\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[xs[0]],\n",
    "            y=[ys[0]],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"red\", size=10),\n",
    "            name=\"Current Position\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# update layout parameters and add start button for animation\n",
    "fig.update_layout(\n",
    "    width=1400,\n",
    "    height=900,\n",
    "    xaxis=dict(range=(x_min, x_max), autorange=False),\n",
    "    yaxis=dict(\n",
    "        range=(np.min(y_measured) - 0.5, np.max(y_measured) + 0.5), autorange=False\n",
    "    ),\n",
    "    title_text=\"Gradient Descent Animation\",\n",
    "    # start button config\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 5, \"redraw\": False},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"transition\": {\"duration\": 0, \"easing\": \"linear\"},\n",
    "                        },\n",
    "                    ],\n",
    "                    label=\"start\",\n",
    "                    method=\"animate\",\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# specify the animation frames\n",
    "fig.update(\n",
    "    frames=[\n",
    "        go.Frame(data=[go.Scatter(x=[xs[k]], y=[ys[k]])], traces=[1])\n",
    "        for k in range(len(ys))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# show result\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-11-18 \n",
    "\n",
    "Bisherige Ansatz hat folgende Limitierungen\n",
    "- funktioniert nur f체r Ausdr체cke in geschlossener Form, keine Kontrollflusslogik\n",
    "- inkompatibel mit bin채ren Operatoren (+, *, ...)\n",
    "- funktioniert nur in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class Value:\n",
    "    def __init__(\n",
    "        self, value: float, ancestors: tuple[Value, ...] = (), name=\"\", operand=\"\"\n",
    "    ):\n",
    "        self.value = value\n",
    "        self.ancestors = ancestors\n",
    "        self.name = name\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self.operand = operand\n",
    "        # TODO add separate nodes for operations\n",
    "\n",
    "    # make values printable\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}, value={self.value}, grad={self.grad}\"\n",
    "\n",
    "    # Addition\n",
    "    def __add__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value + other.value, (self, other), name=\"add\", operand=\"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * result.grad\n",
    "            other.grad += 1.0 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __iadd__(self, other: Value):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "\n",
    "        self.value += other.value\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * self.grad  # Self gradient should continue accumulating\n",
    "            other.grad += 1.0 * self.grad\n",
    "\n",
    "        self._backward = _backward\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __radd__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        return self.value + other.value\n",
    "\n",
    "    # Subtraktion\n",
    "    def __sub__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value - other.value, (self, other), name=\"sub\", operand=\"-\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * result.grad\n",
    "            other.grad += -1.0 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Multiplikation\n",
    "    def __mul__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value * other.value, (self, other), name=\"mul\", operand=\"*\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * result.grad\n",
    "            other.grad += self.value * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Floatingpointdivision\n",
    "    def __truediv__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value / other.value, (self, other), name=\"div\", operand=\"/\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1 / other.value * result.grad\n",
    "            other.grad += -self.value / other.value**2 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Potenzierung (x**n)\n",
    "    def __pow__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value**other.value, (self, other), name=\"pow\", operand=\"^\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * self.value ** (other.value - 1) * result.grad\n",
    "            assert self.value >= 0, \"cannot compute log with negative bases\"\n",
    "            other.grad += self.value**other.value * np.log(self.value) * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # backwards up until this point\n",
    "    # Negation\n",
    "    def __neg__(self) -> Value:\n",
    "        result = Value(-self.value, (self,), name=\"neg\", operand=\"-\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += -result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Vergleichsoperatoren <, >, >=, <=, ==, !=\n",
    "    def __lt__(self, other: Value) -> bool:\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __gt__(self, other: Value) -> bool:\n",
    "        return self.value > other.value\n",
    "\n",
    "    def __le__(self, other: Value) -> bool:\n",
    "        return self.value <= other.value\n",
    "\n",
    "    def __ge__(self, other: Value) -> bool:\n",
    "        return self.value >= other.value\n",
    "\n",
    "    def __eq__(self, other: Value) -> bool:\n",
    "        return self.value == other.value\n",
    "\n",
    "    def __ne__(self, other: Value) -> bool:\n",
    "        return self.value != other.value\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.value)\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        # iterate through the graph, calculate gradients and update nodes\n",
    "        topo_sorted_nodes = []\n",
    "        visited = set()\n",
    "\n",
    "        # topological sort of the nodes\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                for ancestor in node.ancestors:\n",
    "                    build_topo(ancestor)\n",
    "                topo_sorted_nodes.append(node)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo_sorted_nodes):\n",
    "            node._backward()\n",
    "\n",
    "    def build_graph(self) -> dict:\n",
    "        def build_node(node) -> dict:\n",
    "            label = node.__repr__()\n",
    "            node_info = {\n",
    "                \"node\": node,\n",
    "                \"ancestors\": [build_node(ancestor) for ancestor in node.ancestors],\n",
    "                \"operand\": node.operand,\n",
    "            }\n",
    "            return {label: node_info}\n",
    "\n",
    "        return build_node(self)\n",
    "\n",
    "    def plot_graph(self):\n",
    "        # \"graph visualization python\", graphviz\n",
    "        dot = graphviz.Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
    "\n",
    "        def add_nodes(dot: graphviz.Digraph, node: Value):\n",
    "            label = f\"{node.name}|value={node.value}|grad={node.grad}\"\n",
    "            unique_node_name = str(id(node))\n",
    "\n",
    "            # add value nodes to graph\n",
    "            dot.node(\n",
    "                name=unique_node_name,\n",
    "                label=label,\n",
    "                shape=\"record\",\n",
    "                color=\"lightgreen\" if node.ancestors == () else None,  # check if input\n",
    "                style=\"filled\",\n",
    "            )\n",
    "\n",
    "            if node.operand:  # check if there is an operand to display\n",
    "                op_name = unique_node_name + node.operand\n",
    "                # add operation node\n",
    "                dot.node(\n",
    "                    name=op_name,\n",
    "                    label=node.operand,\n",
    "                )\n",
    "                # draw edge from operand to result\n",
    "                dot.edge(op_name, unique_node_name)\n",
    "\n",
    "            # iterate through the ancestors to build the whole graph\n",
    "            for ancestor in node.ancestors:\n",
    "                ancestor_name = add_nodes(dot, ancestor)\n",
    "                if node.operand:\n",
    "                    # ensure ancestor edge goes to operand node if it exists\n",
    "                    dot.edge(ancestor_name, op_name)\n",
    "                else:\n",
    "                    dot.edge(ancestor_name, unique_node_name)\n",
    "\n",
    "            return unique_node_name\n",
    "\n",
    "        add_nodes(dot, self)\n",
    "        display(dot)\n",
    "\n",
    "    # def trace_graph(self) -> tuple[set, set]:\n",
    "    #     nodes, edges = set(), set()\n",
    "\n",
    "    #     def build_graph(node):\n",
    "    #         if node not in nodes:\n",
    "    #             nodes.add(node)\n",
    "    #             for ancestor in node.ancestors:\n",
    "    #                 edges.add((ancestor, node))\n",
    "    #                 build_graph(ancestor)\n",
    "\n",
    "    #     build_graph(self)\n",
    "\n",
    "    #     return nodes, edges\n",
    "\n",
    "    # def draw_graph(self):\n",
    "    #     dot = graphviz.Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
    "\n",
    "    #     nodes, edges = self.trace_graph()\n",
    "    #     for n in nodes:\n",
    "    #         uid = str(id(n))\n",
    "    #         dot.node(\n",
    "    #             name=uid,\n",
    "    #             label=n.__repr__(),\n",
    "    #             shape=\"record\",\n",
    "    #             color=\"lightblue\" if n.ancestors == () else None,\n",
    "    #             style=\"filled\",\n",
    "    #         )\n",
    "    #         if n.operand:\n",
    "    #             dot.node(name=uid + n.operand, label=n.operand)\n",
    "    #             dot.edge(uid + n.operand, uid)\n",
    "\n",
    "    #     for n1, n2 in edges:\n",
    "    #         dot.edge(str(id(n1)), str(id(n2)) + n2.operand)\n",
    "\n",
    "    #     return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.5, name=\"a\")\n",
    "b = Value(3.0, name=\"b\")\n",
    "c = Value(1.5, name=\"c\")\n",
    "\n",
    "\n",
    "def foo(a: Value, b: Value, c: Value):\n",
    "    if a > Value(2):\n",
    "        return a * b + c\n",
    "    return a - b * c\n",
    "\n",
    "\n",
    "z1 = foo(a, b, c)\n",
    "graph = z1.build_graph()\n",
    "z1.plot_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "x = Value(5.0, name=\"x\")\n",
    "y_measured = Value(2.5, name=\"y\")\n",
    "\n",
    "a = Value(2.5, name=\"a\")\n",
    "b = Value(3.0, name=\"b\")\n",
    "c = Value(1.5, name=\"c\")\n",
    "\n",
    "# Folgendes sollte ausf체hbar sein:\n",
    "print(x + y_measured)\n",
    "print(x * y_measured)\n",
    "print(x - y_measured)\n",
    "print(x / y_measured)\n",
    "print(x**y_measured)\n",
    "print(x**5)\n",
    "print(-x)\n",
    "print(x == y_measured)\n",
    "\n",
    "\n",
    "def foo(a: Value, b: Value, c: Value):\n",
    "    if a > Value(2):\n",
    "        return a * b + c\n",
    "    return a - b * c\n",
    "\n",
    "\n",
    "def f(a: Value, b: Value, c: Value) -> float:\n",
    "    # (((b**2) * c) + a)\n",
    "    x = b**2 * c\n",
    "    y = a + x\n",
    "    return y\n",
    "\n",
    "\n",
    "z1 = foo(a, b, c)\n",
    "graph = z1.build_graph()\n",
    "z1.plot_graph()\n",
    "\n",
    "z2 = foo(Value(-1, name=\"a2\"), b, c)\n",
    "graph = z2.build_graph()\n",
    "z2.plot_graph()\n",
    "\n",
    "z3 = f(a, b, c)\n",
    "graph = z3.build_graph()\n",
    "z3.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1.backward()\n",
    "graph = z1.build_graph()\n",
    "Value.plot_graph(graph)\n",
    "\n",
    "z3.backward()\n",
    "graph3 = z3.build_graph()\n",
    "Value.plot_graph(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct(x, y):\n",
    "    return (x + y) ** 2\n",
    "\n",
    "\n",
    "x = Value(2.5, name=\"x\")\n",
    "y_measured = Value(5.0, name=\"y\")\n",
    "\n",
    "vals = funct(x, y_measured)\n",
    "vals.backward()\n",
    "Value.plot_graph(vals.build_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "np.random.seed(0xDEADBEEF)\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y_ideal = 2 * x - 2\n",
    "y_measured = y_ideal + np.random.randn(len(x)) * 1.5\n",
    "\n",
    "fig = px.scatter(x=x, y=y_measured)\n",
    "fig.add_trace(go.Scatter(x=x, y=y_ideal, mode=\"lines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lineare Regression f(x) = m*x + c\n",
    "\n",
    "# Random init von m und c\n",
    "m = Value(np.random.random_sample(size=None) * 5, name=\"slope\")\n",
    "c = Value(np.random.random_sample(size=None) * 5, name=\"intercept\")\n",
    "\n",
    "\n",
    "# Lossfunktion definieren\n",
    "def loss(m: Value, c: Value) -> Value:\n",
    "    # sum_error = sum((m * x + c) - y_measured) ** 2\n",
    "    sum_error = 0.0\n",
    "    for ii, sample in enumerate(x):\n",
    "        sample_error = (m * sample + c - y_measured[ii]) ** 2\n",
    "        sum_error += sample_error\n",
    "    return sum_error\n",
    "\n",
    "\n",
    "# Hyperparameter\n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "ms = []\n",
    "cs = []\n",
    "\n",
    "# Trainingloop\n",
    "# - Zwischenergebnisse von (m und c) speichern\n",
    "# - Zwischenergebnisse visualisieren (Animation?)\n",
    "for i in range(epochs):\n",
    "\n",
    "    precision_loss = Value(loss(m, c))\n",
    "    precision_loss.name = \"Out\"\n",
    "\n",
    "    m.grad = 0\n",
    "    c.grad = 0\n",
    "    precision_loss.backward()\n",
    "\n",
    "    m.value -= lr * m.grad\n",
    "    c.value -= lr * c.grad\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\n",
    "            f\"epoch {i}: loss = {precision_loss.value, precision_loss.grad, precision_loss.ancestors}, m = {m.value, m.grad}, c = {c.value, c.grad}\"\n",
    "        )\n",
    "        ms.append(m.value)\n",
    "        cs.append(c.value)\n",
    "\n",
    "print(f\"final m: {m.value}, final c: {c.value}, final loss: {precision_loss.value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diy-mnist-nn-ZXZBkNkJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
