{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Literal\n",
    "import time\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(\n",
    "        self, value: float, ancestors: tuple[Value, ...] = (), name=\"\", operand=\"\"\n",
    "    ):\n",
    "        self.value = value\n",
    "        self.ancestors = ancestors\n",
    "        self.name = name\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self.operand = operand\n",
    "\n",
    "    # make values printable\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}, value={self.value}, grad={self.grad}\"\n",
    "\n",
    "    # Addition\n",
    "    def __add__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value + other.value, (self, other), name=\"add\", operand=\"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += result.grad\n",
    "            other.grad += result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __iadd__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(\n",
    "            self.value + other.value, (self, other), name=\"iadd\", operand=\"+=\"\n",
    "        )\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += result.grad\n",
    "            other.grad += result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    # Subtraktion\n",
    "    def __sub__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value - other.value, (self, other), name=\"sub\", operand=\"-\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * result.grad\n",
    "            other.grad += -1.0 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __rsub__(self, other) -> Value:\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise NotImplementedError()\n",
    "        return Value(other) - self\n",
    "\n",
    "    # Multiplikation\n",
    "    def __mul__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value * other.value, (self, other), name=\"mul\", operand=\"*\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * result.grad\n",
    "            other.grad += self.value * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __rmul__(self, other) -> Value:\n",
    "        return self * other\n",
    "\n",
    "    # Floatingpointdivision\n",
    "    def __truediv__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value / other.value, (self, other), name=\"div\", operand=\"/\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1 / other.value * result.grad\n",
    "            other.grad += -self.value / other.value**2 * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def __rtruediv__(self, other) -> Value:\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise NotImplementedError()\n",
    "        return Value(other) / self\n",
    "\n",
    "    # Potenzierung (x**n)\n",
    "    def __pow__(self, other: Value) -> Value:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        result = Value(self.value**other.value, (self, other), name=\"pow\", operand=\"^\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.value * self.value ** (other.value - 1.0) * result.grad\n",
    "            # assert self.value >= 0, \"cannot compute log with negative base\n",
    "            other.grad += self.value**other.value * np.log(self.value) * result.grad\n",
    "            # print(self.grad, other.grad)\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Exponentierung (e**x)\n",
    "    def exp(self) -> Value:\n",
    "        result = Value(np.exp(self.value), (self,), name=\"exp\", operand=\"e^\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += result.value * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def log(self) -> Value:\n",
    "        result_value = np.log(self.value)\n",
    "        result = Value(result_value, (self,), name=\"log\")\n",
    "\n",
    "        def _backward():\n",
    "            if self.value > 0:\n",
    "                self.grad += (1 / self.value) * result.grad\n",
    "            else:\n",
    "                self.grad += 0.0  # Gradient is zero for non-positive input\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Negation\n",
    "    def __neg__(self) -> Value:\n",
    "        result = Value(-self.value, (self,), name=\"neg\", operand=\"-\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += -result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    def sigmoid(self) -> Value:\n",
    "        sigmoid_value = 1 / (1 + np.exp(-self.value))\n",
    "        result = Value(sigmoid_value, (self,), name=\"sigmoid\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += sigmoid_value * (1 - sigmoid_value) * result.grad\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # how to fix backward with ne values\n",
    "    def relu(self) -> Value:\n",
    "        result_value = self.value if self.value > 0 else 0.0\n",
    "        result = Value(result_value, (self,), name=\"ReLU\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += self.value * result.grad if self.value > 0 else 0.0\n",
    "\n",
    "        result._backward = _backward\n",
    "        return result\n",
    "\n",
    "    # Vergleichsoperatoren <, >, >=, <=\n",
    "    def __lt__(self, other: Value) -> bool:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __gt__(self, other: Value) -> bool:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        return self.value > other.value\n",
    "\n",
    "    def __le__(self, other: Value) -> bool:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        return self.value <= other.value\n",
    "\n",
    "    def __ge__(self, other: Value) -> bool:\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        return self.value >= other.value\n",
    "\n",
    "    def backward(self) -> None:\n",
    "        # iterate through the graph, calculate gradients and update nodes\n",
    "        topo_sorted_nodes = []\n",
    "        visited = set()\n",
    "\n",
    "        # topological sort of the nodes\n",
    "        def build_topo(node: Value):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                for ancestor in node.ancestors:\n",
    "                    build_topo(ancestor)\n",
    "                topo_sorted_nodes.append(node)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo_sorted_nodes):\n",
    "            node._backward()\n",
    "\n",
    "    def plot_graph(self):\n",
    "        # \"graph visualization python\", graphviz\n",
    "        dot = graphviz.Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
    "\n",
    "        def add_nodes(dot: graphviz.Digraph, node: Value):\n",
    "            label = f\"{node.name}|value={node.value}|grad={node.grad}\"\n",
    "            unique_node_name = str(id(node))\n",
    "\n",
    "            # add value nodes to graph\n",
    "            dot.node(\n",
    "                name=unique_node_name,\n",
    "                label=label,\n",
    "                shape=\"record\",\n",
    "                color=(\n",
    "                    \"lightgreen\" if node.ancestors == () and node.name != \"\" else None\n",
    "                ),  # check if input\n",
    "                style=\"filled\",\n",
    "            )\n",
    "\n",
    "            if node.operand:  # check if there is an operand to display\n",
    "                op_name = unique_node_name + node.operand\n",
    "                # add operation node\n",
    "                dot.node(\n",
    "                    name=op_name,\n",
    "                    label=node.operand,\n",
    "                )\n",
    "                # draw edge from operand to result\n",
    "                dot.edge(op_name, unique_node_name)\n",
    "\n",
    "            # iterate through the ancestors to build the whole graph\n",
    "            for ancestor in node.ancestors:\n",
    "                ancestor_name = add_nodes(dot, ancestor)\n",
    "                if node.operand:\n",
    "                    # ensure ancestor edge goes to operand node if it exists\n",
    "                    dot.edge(ancestor_name, op_name)\n",
    "                else:\n",
    "                    dot.edge(ancestor_name, unique_node_name)\n",
    "\n",
    "            return unique_node_name\n",
    "\n",
    "        add_nodes(dot, self)\n",
    "        display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mnist_data(\n",
    "    idx_file_training_samples: str,\n",
    "    idx_file_training_labels: str,\n",
    "    number_1: int,\n",
    "    number_2: int,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    training_labels = parse_mnist_labels(idx_file_training_labels)\n",
    "    training_samples = parse_mnist_images(idx_file_training_samples)\n",
    "\n",
    "    # filter only two numbers with a mask\n",
    "    mask = (training_labels.flatten() == number_1) | (\n",
    "        training_labels.flatten() == number_2\n",
    "    )\n",
    "    filtered_labels = training_labels[mask]\n",
    "    filtered_samples = training_samples[mask]\n",
    "\n",
    "    # Image.resize() Algorithmus -> Recherche\n",
    "    # -LANCZOS als Algorithmus zur Bildverkleinerung -> sinc(x) = sin(πx) / (πx)\n",
    "    # -gemacht zum downscalen von Bildern ->\n",
    "    # downscale images with pillow\n",
    "    downscaled_samples = np.array(\n",
    "        # Image.Resampling.LANCZOS\n",
    "        [\n",
    "            Image.fromarray(img).resize((10, 10), Image.Resampling.LANCZOS)\n",
    "            for img in filtered_samples\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    downscaled_samples = downscaled_samples / 255\n",
    "\n",
    "    return downscaled_samples, filtered_labels\n",
    "\n",
    "\n",
    "def parse_mnist_images(idx_file_path: str) -> np.ndarray:\n",
    "    with open(idx_file_path, \"rb\") as f:\n",
    "\n",
    "        # read magic number\n",
    "        f.read(4)\n",
    "        num_img = int.from_bytes(f.read(4), \"big\")\n",
    "        num_rows = int.from_bytes(f.read(4), \"big\")\n",
    "        num_cols = int.from_bytes(f.read(4), \"big\")\n",
    "\n",
    "        data = f.read()\n",
    "        out = np.ndarray((num_img, num_rows, num_cols), np.uint8, data)\n",
    "        return out\n",
    "\n",
    "\n",
    "def parse_mnist_labels(idx_file_path: str) -> np.ndarray:\n",
    "    with open(idx_file_path, \"rb\") as f:\n",
    "\n",
    "        # read magic number\n",
    "        f.read(4)\n",
    "        num_item = int.from_bytes(f.read(4), \"big\")\n",
    "\n",
    "        data = f.read()\n",
    "        out = np.ndarray((num_item, 1), np.uint8, data)\n",
    "        return out\n",
    "\n",
    "\n",
    "def plot_image(img: np.ndarray) -> plt.Figure:\n",
    "    assert len(img.shape) == 2, \"input must be 2-dimensional (single image)\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img * 255, cmap=\"gray\")\n",
    "\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0xDEADBEEF)\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs: int) -> None:\n",
    "        self.weights = [Value(np.random.randn()) for _ in range(num_inputs)]\n",
    "        self.bias = Value(0.0, name=\"bias\")\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> Value:\n",
    "        # implement f(x) = activation (bias + sum(weights * values))\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = x.flatten()\n",
    "        res = sum(w_i * x_i for w_i, x_i in zip(self.weights, x)) + self.bias\n",
    "        return res\n",
    "\n",
    "    def parameters(self) -> list[Value]:\n",
    "        return self.weights + [self.bias]\n",
    "\n",
    "    def param_count(self) -> int:\n",
    "        return len(self.weights + [self.bias])\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_inputs: int,\n",
    "        num_outputs: int,\n",
    "        use_activation: Literal[\"relu\", \"sigmoid\"],\n",
    "    ) -> None:\n",
    "        self.neurons = [Neuron(num_inputs) for _ in range(num_outputs)]\n",
    "        self.use_activation = use_activation\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> list[Value]:\n",
    "        outputs = [n(x) for n in self.neurons]\n",
    "        if self.use_activation == \"relu\":\n",
    "            return [o.relu() for o in outputs]\n",
    "        return [o.sigmoid() for o in outputs]\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        params = [p for n in self.neurons for p in n.parameters()]\n",
    "        return params\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, num_inputs: int, num_hidden: list[int], num_out: int) -> None:\n",
    "        size = [num_inputs] + num_hidden\n",
    "        self.layers = [\n",
    "            Layer(size[i], size[i + 1], \"relu\") for i in range(len(num_hidden))\n",
    "        ] + [Layer(num_hidden[-1], num_out, \"sigmoid\")]\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> Value:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x[0]\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        params = [p for l in self.layers for p in l.parameters()]\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_loss(y_pred: Value, y_gt) -> Value:\n",
    "    y_gt = Value(y_gt.item(), (), name=\"ground truth\")\n",
    "    loss = (y_gt - y_pred) ** 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_pred: Value, y_gt) -> Value:\n",
    "    eps = 1e-15\n",
    "\n",
    "    if y_gt == 0:\n",
    "        return -((1 - y_pred + eps).log())\n",
    "    else:\n",
    "        return -((y_pred + eps).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_loss_and_accuracy(\n",
    "    mlp: MLP, images: np.ndarray, labels: np.ndarray\n",
    ") -> tuple[float, float]:\n",
    "    loss = 0\n",
    "    correct_pred = 0\n",
    "    for image, label in zip(images, labels):\n",
    "        pred = mlp(image)\n",
    "\n",
    "        loss += cross_entropy_loss(pred, label)\n",
    "\n",
    "        if np.fabs(pred.value - label.item()) < 0.5:\n",
    "            correct_pred += 1.0\n",
    "\n",
    "    return loss / len(images), correct_pred / len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "train_img_path = \"../data/train_img.idx\"\n",
    "train_label_path = \"../data/train_label.idx\"\n",
    "test_img_path = \"../data/test_img.idx\"\n",
    "test_label_path = \"../data/test_label.idx\"\n",
    "\n",
    "train_img, train_label = parse_mnist_data(train_img_path, train_label_path, 0, 1)\n",
    "# only get the first 1000 images and labels\n",
    "train_img = train_img[:100]\n",
    "train_label = train_label[:100]\n",
    "\n",
    "test_img, test_label = parse_mnist_data(test_img_path, test_label_path, 0, 1)\n",
    "test_img = test_img[:10]\n",
    "test_label = test_label[:10]\n",
    "\n",
    "# initialize MLP\n",
    "nin = 100\n",
    "n_hidden = [10]\n",
    "nout = 1\n",
    "mlp = MLP(nin, n_hidden, nout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Python Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0xDEADBEEF)\n",
    "# Hyperparameter\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "num_img = train_img.shape[0]\n",
    "num_batches = math.ceil(num_img / batch_size)\n",
    "\n",
    "# Plot Parameter\n",
    "losses_test = []\n",
    "losses_train = []\n",
    "accuracies_test = []\n",
    "accuracies_train = []\n",
    "times = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    idx = np.random.permutation(np.arange(num_img))\n",
    "    # inplace for better cache usage TODO\n",
    "    train_img = train_img[idx]\n",
    "    train_label = train_label[idx]\n",
    "\n",
    "    # Genauigkeit & Loss berechnen 1 pro Epoche für Plot\n",
    "    print(\"calculating accuracies and losses...\")\n",
    "    train_loss, train_accuracy = epoch_loss_and_accuracy(\n",
    "        mlp=mlp, images=train_img, labels=train_label\n",
    "    )\n",
    "    test_loss, test_accuracy = epoch_loss_and_accuracy(\n",
    "        mlp=mlp, images=test_img, labels=test_label\n",
    "    )\n",
    "    losses_train.append(train_loss)\n",
    "    losses_test.append(test_loss)\n",
    "    accuracies_train.append(train_accuracy)\n",
    "    accuracies_test.append(test_accuracy)\n",
    "    print(\"...done\")\n",
    "\n",
    "    # Epochendauer ausgeben\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        batch_start_time = time.process_time()\n",
    "        start_sample = b * batch_size\n",
    "        end_sample = min((b + 1) * batch_size, num_img)\n",
    "        x = train_img[start_sample:end_sample]\n",
    "        y_gt = train_label[start_sample:end_sample]\n",
    "\n",
    "        # zero grad\n",
    "        for p in mlp.parameters():\n",
    "            p.grad = 0.0\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = [mlp(img) for img in x]\n",
    "\n",
    "        # backward pass\n",
    "        outputs = [cross_entropy_loss(ypred, ygt) for ypred, ygt in zip(y_pred, y_gt)]\n",
    "        loss = sum(outputs) / len(outputs)\n",
    "        loss.backward()\n",
    "\n",
    "        # if b % 10 == 0 or b + 1 == num_batches:\n",
    "        #     print(f\"Epoche: {e+1}, Batch: {b+1} / {num_batches} Loss: {loss.value}\")\n",
    "\n",
    "        losses_train.append(loss.value)\n",
    "\n",
    "        # optimization\n",
    "        for p in mlp.parameters():\n",
    "            # print(p.grad)\n",
    "            p.value -= lr * p.grad\n",
    "        batch_end_time = time.process_time()\n",
    "        print(\n",
    "            f\"Batchdauer: {batch_end_time-batch_start_time}, {end_sample-start_sample}\"\n",
    "        )\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    times.append(end_time - start_time)\n",
    "    print(f\"Epoche {e+1}: {times[e]} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=range(len(times)), y=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=range(len(losses_train)), y=losses_train, log_y=True)\n",
    "fig.add_trace(go.Scatter(x=range(len(losses_test)), y=losses_test, mode=\"lines\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=range(len(accuracies_train)), y=accuracies_train)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=range(len(accuracies_test)), y=accuracies_test, mode=\"lines\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0xDEADBEEF)\n",
    "n = Neuron(10)\n",
    "inp = np.random.randint(0, 11, (10, 10)) / 10\n",
    "y_ground_truth = np.random.randint(0, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 5\n",
    "lr = 10\n",
    "num_img = inp.shape[0]\n",
    "num_batches = int(num_img / batch_size)\n",
    "losses_n = []\n",
    "\n",
    "print(n.parameters())\n",
    "\n",
    "for e in range(epochs):\n",
    "    for b in range(num_batches):\n",
    "        start_sample = b * batch_size\n",
    "        end_sample = min((b + 1) * batch_size, num_img)\n",
    "\n",
    "        x_n = inp[start_sample:end_sample]\n",
    "        y_n = y_ground_truth[start_sample:end_sample]\n",
    "\n",
    "        for p in n.parameters():\n",
    "            p.grad = 0.0\n",
    "\n",
    "        # forward\n",
    "        y_pred_n = [n(img).sigmoid() for img in x_n]\n",
    "\n",
    "        # calculate loss\n",
    "        out_losses = [\n",
    "            cross_entropy_loss(ypredn, yn) for ypredn, yn in zip(y_pred_n, y_n)\n",
    "        ]\n",
    "        loss = sum(out_losses) / len(out_losses)\n",
    "        losses_n.append(loss.value)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        for p in n.parameters():\n",
    "            p.value -= lr * p.grad\n",
    "\n",
    "print(n.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=range(len(losses_n)), y=losses_n, log_y=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diy-mnist-nn-ZXZBkNkJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
