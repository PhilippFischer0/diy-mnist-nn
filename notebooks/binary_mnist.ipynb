{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "from src import *\n",
    "from src.value import *\n",
    "import numpy as np\n",
    "import time, math, json\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "train_img_path = \"../data/train_img.idx\"\n",
    "train_label_path = \"../data/train_label.idx\"\n",
    "test_img_path = \"../data/test_img.idx\"\n",
    "test_label_path = \"../data/test_label.idx\"\n",
    "\n",
    "train_img, train_label, test_img, test_label = binary_parse_mnist_data(\n",
    "    train_img_path, train_label_path, test_img_path, test_label_path, 0, 1\n",
    ")\n",
    "\n",
    "# get equally distributed images and labels\n",
    "train_img, train_label = get_number_of_samples(train_img, train_label, 90)\n",
    "test_img, test_label = get_number_of_samples(test_img, test_label, 90)\n",
    "\n",
    "# initialize MLP\n",
    "nin = 100\n",
    "n_hidden = [10, 10]\n",
    "nout = 1\n",
    "mlp = MLP(nin, n_hidden, nout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0xDEADBEEF)\n",
    "# Hyperparameter\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "num_img = train_img.shape[0]\n",
    "num_batches = math.ceil(num_img / batch_size)\n",
    "\n",
    "# Plot Parameter\n",
    "losses_test = []\n",
    "losses_train = []\n",
    "accuracies_test = []\n",
    "accuracies_train = []\n",
    "times = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    idx = np.random.permutation(np.arange(num_img))\n",
    "    # inplace for better cache usage\n",
    "    train_img = train_img[idx]\n",
    "    train_label = train_label[idx]\n",
    "    test_img = test_img[idx]\n",
    "    test_label = test_label[idx]\n",
    "\n",
    "    # Genauigkeit & Loss berechnen 1 pro Epoche für Plot\n",
    "    print(\"calculating accuracies and losses...\")\n",
    "    train_loss, train_accuracy = mlp.epoch_loss_and_accuracy(\n",
    "        images=train_img, labels=train_label\n",
    "    )\n",
    "    test_loss, test_accuracy = mlp.epoch_loss_and_accuracy(\n",
    "        images=test_img, labels=test_label\n",
    "    )\n",
    "    losses_train.append(train_loss.value)\n",
    "    losses_test.append(test_loss.value)\n",
    "    accuracies_train.append(train_accuracy)\n",
    "    accuracies_test.append(test_accuracy)\n",
    "    print(\"...done\")\n",
    "\n",
    "    # Epochendauer ausgeben\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        batch_start_time = time.process_time()\n",
    "        start_sample = b * batch_size\n",
    "        end_sample = min((b + 1) * batch_size, num_img)\n",
    "        x = train_img[start_sample:end_sample]\n",
    "        y_gt = train_label[start_sample:end_sample]\n",
    "\n",
    "        # zero grad\n",
    "        for p in mlp.parameters():\n",
    "            p.grad = 0.0\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = [mlp(img) for img in x]\n",
    "\n",
    "        # backward pass\n",
    "        outputs = [\n",
    "            Value.cross_entropy_loss(ypred, ygt) for ypred, ygt in zip(y_pred, y_gt)\n",
    "        ]\n",
    "        loss = sum(outputs) / len(outputs)\n",
    "        loss.backward()\n",
    "\n",
    "        # optimization\n",
    "        for p in mlp.parameters():\n",
    "            p.value -= lr * p.grad\n",
    "        batch_end_time = time.process_time()\n",
    "        print(\n",
    "            f\"Batchdauer: {batch_end_time-batch_start_time}, Size: {end_sample-start_sample}\"\n",
    "        )\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    times.append(end_time - start_time)\n",
    "    print(f\"Epoche {e+1}: {times[e]} s\")\n",
    "\n",
    "time_df = pd.DataFrame(\n",
    "    {\n",
    "        \"epochs\": range(epochs),\n",
    "        \"times\": times,\n",
    "    }\n",
    ")\n",
    "\n",
    "loss_df = pd.DataFrame(\n",
    "    {\n",
    "        \"epochs\": range(epochs),\n",
    "        \"train_loss\": losses_train,\n",
    "        \"test_loss\": losses_test,\n",
    "    }\n",
    ")\n",
    "\n",
    "acc_df = pd.DataFrame(\n",
    "    {\n",
    "        \"epochs\": range(epochs),\n",
    "        \"train_acc\": accuracies_train,\n",
    "        \"test_acc\": accuracies_test,\n",
    "    }\n",
    ")\n",
    "\n",
    "loss_df = loss_df.melt(\n",
    "    id_vars=\"epochs\", value_vars=[\"train_loss\", \"test_loss\"], value_name=\"loss\"\n",
    ")\n",
    "acc_df = acc_df.melt(\n",
    "    id_vars=\"epochs\", value_vars=[\"train_acc\", \"test_acc\"], value_name=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(time_df, x=\"epochs\", y=\"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(loss_df, x=\"epochs\", y=\"loss\", color=\"variable\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(acc_df, x=\"epochs\", y=\"accuracy\", color=\"variable\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_label, test_img, test_label = binary_parse_mnist_data(\n",
    "    train_img_path, train_label_path, test_img_path, test_label_path, 0, 1\n",
    ")\n",
    "\n",
    "train_img, train_label = get_number_of_samples(train_img, train_label, 900)\n",
    "test_img, test_label = get_number_of_samples(test_img, test_label, 900)\n",
    "# initialize MLP\n",
    "nin = 100\n",
    "n_hidden = [10, 10]\n",
    "nout = 1\n",
    "mlp2 = MLP(nin, n_hidden, nout)\n",
    "\n",
    "# Hyperparameter\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "num_img = train_img.shape[0]\n",
    "num_batches = math.ceil(num_img / batch_size)\n",
    "\n",
    "count_epochs = 0\n",
    "timer = 0\n",
    "datas = []\n",
    "\n",
    "# langer Durchlauf -> Plot Werte periodisch in Datei\n",
    "while True:\n",
    "    idx = np.random.permutation(np.arange(num_img))\n",
    "    # inplace for better cache usage\n",
    "    train_img = train_img[idx]\n",
    "    train_label = train_label[idx]\n",
    "\n",
    "    test_img = test_img[idx]\n",
    "    test_label = test_label[idx]\n",
    "\n",
    "    # Genauigkeit & Loss berechnen 1 pro 100 Epochen für Plot\n",
    "\n",
    "    train_loss, train_accuracy = mlp2.epoch_loss_and_accuracy(\n",
    "        images=train_img, labels=train_label\n",
    "    )\n",
    "    test_loss, test_accuracy = mlp2.epoch_loss_and_accuracy(\n",
    "        images=test_img, labels=test_label\n",
    "    )\n",
    "    # TODO Accuracy, Loss und Timer in Datei Schreiben\n",
    "    data = {\n",
    "        \"epoch\": count_epochs,\n",
    "        \"time\": timer,\n",
    "        \"train_loss\": train_loss.value,\n",
    "        \"train_acc\": train_accuracy,\n",
    "        \"test_loss\": test_loss.value,\n",
    "        \"test_acc\": test_accuracy,\n",
    "    }\n",
    "    datas.append(data)\n",
    "    with open(\"../data/log_training.json\", \"w\") as out:\n",
    "        json.dump(datas, out, indent=4)\n",
    "    # Epochendauer ausgeben\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        start_sample = b * batch_size\n",
    "        end_sample = min((b + 1) * batch_size, num_img)\n",
    "        x = train_img[start_sample:end_sample]\n",
    "        y_gt = train_label[start_sample:end_sample]\n",
    "\n",
    "        # zero grad\n",
    "        for p in mlp2.parameters():\n",
    "            p.grad = 0.0\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = [mlp2(img) for img in x]\n",
    "\n",
    "        # backward pass\n",
    "        outputs = [\n",
    "            Value.cross_entropy_loss(ypred, ygt) for ypred, ygt in zip(y_pred, y_gt)\n",
    "        ]\n",
    "        loss = sum(outputs) / len(outputs)\n",
    "        loss.backward()\n",
    "\n",
    "        # optimization\n",
    "        for p in mlp2.parameters():\n",
    "            p.value -= lr * p.grad\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    timer = end_time - start_time\n",
    "    count_epochs += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diy-mnist-nn-ZXZBkNkJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
